# RAG実装調査

## 目的

ローカル環境でRAG(Retrieval-Augmented Generation)を構築し、MCPから参照できるようにすることで、プロジェクト固有の情報を活用したコード生成の品質向上を目指す。

## 実現したいこと

1. ローカル環境でRAGを構築しMCPで参照できるようにする
2. RAGにプロジェクト固有の情報を溜め込む（チーム固有のルールや規約、利用する技術の公式ドキュメント情報など）
3. Claude等のツールからMCPを経由して情報を呼び出し、生成されるコードに改善が見られるか検証する

## 技術スタック

- RAG構築用フレームワーク: LangChain.js
- 埋め込みモデル: [pfnet/plamo-embedding-1b](https://huggingface.co/pfnet/plamo-embedding-1b)
- 埋め込みモデル実行環境: LM Studio
- 動作環境: M4 Macbook Pro

## RAGの基本概念と構成要素

RAG（Retrieval-Augmented Generation）は、生成AIモデルの回答品質を向上させるために、外部知識ベースから関連情報を検索・取得し、その情報を基に回答を生成する手法です。

### 主要コンポーネント

1. **ベクトルデータベース**: ドキュメントの埋め込みベクトルを格納
2. **埋め込みモデル**: テキストをベクトル表現に変換
3. **検索エンジン**: 類似ベクトルの検索
4. **生成モデル**: 検索結果を利用した回答生成

## 実装アプローチの検討

### 1. LangChain.jsを使用したRAG実装

LangChain.jsはJavaScriptベースのLLMアプリケーション開発フレームワークで、RAG実装に必要な多くのコンポーネントを提供しています。

#### メリット
- 豊富なドキュメントと実装例
- モジュール化されたコンポーネント
- さまざまなベクトルデータベースとの連携サポート

#### デメリット
- JavaScriptの非同期処理への理解が必要
- 複雑なワークフローを構築する場合は学習コストがかかる

### 2. 埋め込みモデル（plamo-embedding-1b）

日本語と英語に対応した埋め込みモデルで、文書の意味をベクトル空間にマッピングします。

#### 特徴
- 日本語と英語のバイリンガル対応
- サイズ: 約1.62GB
- 埋め込みサイズ: 1024次元
- コンテキスト長: 8192トークン

#### 利用方法
LM Studioを使用してローカルで実行し、APIエンドポイントとして提供します。

### 3. ベクトルデータベースの選択

ローカル環境で簡単に構築できるベクトルデータベースを検討します。

#### 候補
- **DuckDB + VSS**: 高速なクエリ処理とベクトル検索を統合
- **FAISS**: Facebook AI製の高速なベクトル検索ライブラリ
- **Qdrant**: Rustベースの高性能ベクトルDB

初期実装ではDuckDB + VSSを選択することが適切と考えられます：
- SQLベースで柔軟なクエリが可能
- ローカル環境での設定が簡単
- 高速なベクトル検索と分析機能の統合

## 実装計画

### フェーズ1: 基本的なRAGシステムの構築

1. **環境セットアップ**
   - Node.jsプロジェクトの初期化
   - LangChain.jsと必要なパッケージのインストール
   - LM Studioで埋め込みモデルをセットアップ

2. **ドキュメント処理パイプラインの構築**
   - ドキュメントローダーの実装（Markdown、PDF、テキストファイル対応）
   - テキスト分割処理の実装
   - 埋め込みモデルを使用したベクトル変換

3. **ベクトルストアの構築**
   - DuckDB + VSSのセットアップ
   - 埋め込みベクトルの保存と検索機能の実装

4. **クエリインターフェースの実装**
   - RESTful APIエンドポイントの構築
   - MCPとの連携方法の検討

### フェーズ2: MCP連携と評価

1. **MCPとの連携**
   - APIインターフェースの調整
   - 認証メカニズムの実装（必要に応じて）

2. **評価システムの構築**
   - RAGありなしでの生成コードの比較評価手法
   - 定量的・定性的評価指標の設定

3. **最適化**
   - パフォーマンスチューニング
   - 検索精度の向上

## 技術的課題と対応策

### 1. 埋め込みモデルのパフォーマンス

**課題**: M4 MacBook Proでの埋め込みモデル実行のパフォーマンス

**対応策**:
- バッチ処理の最適化
- モデルの量子化を検討
- 処理の分散化（必要に応じて）

### 2. ドキュメント更新の反映

**課題**: プロジェクトドキュメントの更新をRAGシステムに反映する方法

**対応策**:
- ファイル変更検知システムの実装
- 定期的な再インデックス処理
- 差分更新メカニズムの検討

### 3. MCP連携の技術的制約

**課題**: MCPとRAGシステム間の連携方法と制約

**対応策**:
- MCPのAPI仕様の詳細調査
- プロキシサーバーの検討（必要に応じて）
- 適切な認証メカニズムの実装

## 今後の調査事項

1. MCPのAPI仕様と連携方法の詳細調査
2. ベクトルデータベースのパフォーマンス比較（DuckDB + VSS vs FAISS vs Qdrant）
3. 大規模ドキュメントセットのハンドリング手法
4. RAGシステムの評価手法とベンチマーク

## 参考資料

- [LangChain.js ドキュメント](https://js.langchain.com/docs/)
- [pfnet/plamo-embedding-1b](https://huggingface.co/pfnet/plamo-embedding-1b/blob/main/README_ja.md)
- [DuckDB公式ドキュメント](https://duckdb.org/)
- [Retrieval Augmented Generation (RAG): パターンとベストプラクティス](https://www.langchain.com/rag)
